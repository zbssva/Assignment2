### **1. Что понимается под гетерогенной параллелизацией?**

Гетерогенная параллелизация — это способ организации вычислений, при котором используются разные типы процессоров одновременно, чаще всего CPU и GPU.
Идея в том, что разные части программы выполняются там, где это выгоднее:

* CPU выполняет сложную логику, управление программой, условия, ввод-вывод
* GPU выполняет массовые однотипные вычисления над большими объёмами данных

Таким образом, каждый тип процессора делает то, в чём он сильнее, и программа в целом работает быстрее.

---

### **2. В чём принципиальные различия архитектур CPU и GPU?**

Основные различия связаны с устройством и способом выполнения задач:

* CPU
  * Имеет небольшое количество «умных» ядер
  * Хорошо справляется с последовательным кодом
  * Эффективен для сложных условий `if/else`, ветвлений, логики управления

* GPU
  * Имеет тысячи простых ядер
  * Работает по принципу: одно действие — над большим количеством данных
  * Лучше всего подходит для массового параллелизма

Проще говоря, CPU — для управления и логики, GPU — для быстрых однотипных вычислений.

---

### **3. Какие типы задач лучше подходят для выполнения на GPU, а какие — на CPU?**

На GPU лучше выполнять:
* операции с массивами и матрицами
* обработку изображений и видео
* нейронные сети и машинное обучение
* физическое моделирование и численные расчёты

На CPU лучше выполнять:
* алгоритмы с большим количеством условий
* последовательные алгоритмы
* управление программой
* работу с файлами, ввод/вывод

Если задача легко делится на независимые части — она подходит для GPU.
Если требуется много логики и решений — лучше CPU.

---

### **4. Почему не все алгоритмы эффективно распараллеливаются с использованием OpenMP?**

Не все алгоритмы можно эффективно распараллелить, потому что:

* между шагами алгоритма может быть зависимость по данным
* часть кода может быть строго последовательной
* накладные расходы на создание потоков могут быть больше, чем польза
* возможны гонки данных, если неправильно организовать доступ к памяти

Например, если каждый следующий шаг зависит от результата предыдущего, то параллелизм почти невозможен.

---

### **5. В чём заключается основная идея алгоритма сортировки слиянием?**

Сортировка слиянием работает по принципу «разделяй и властвуй»:

1. Массив делится на две части
2. Каждая часть сортируется отдельно
3. Отсортированные части сливаются в один отсортированный массив

Этот процесс повторяется рекурсивно, пока массивы не станут очень маленькими.
Алгоритм стабилен и имеет сложность O(n log n).

---

### **6. Какие сложности возникают при реализации сортировки слиянием на GPU?**

Основные сложности:

* этап слияния сложно распараллелить
* требуется много обращений к памяти
* синхронизация потоков усложняет реализацию
* неравномерное распределение данных между потоками

GPU хорошо работает, когда все потоки делают одно и то же, а при слиянии это условие часто нарушается.

---

### **7. Как выбор размера блока и сетки влияет на производительность вычислений на GPU?**

Размер блока и сетки напрямую влияет на скорость работы:

* слишком маленькие блоки → GPU используется не полностью
* слишком большие блоки → не хватает ресурсов (регистров, памяти)
* правильный размер позволяет:

  * лучше загрузить GPU
  * скрыть задержки доступа к памяти
  * увеличить параллелизм

Поэтому размеры блоков и сетки обычно подбираются экспериментально.

---

### **8. Почему гетерогенный подход может быть эффективнее использования только CPU или только GPU?**

Потому что:

* CPU и GPU дополняют друг друга
* CPU выполняет сложную логику и управление
* GPU ускоряет вычислительно тяжёлые участки
* уменьшается общее время выполнения программы

Использование только CPU или только GPU означает, что часть ресурсов будет использоваться неэффективно.
Гетерогенный подход позволяет максимально использовать возможности всей системы.
