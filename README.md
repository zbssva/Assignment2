# Assignment2 по гетерогенной параллелизации
### Задание 1 — Последовательная версия программы
В первом задании реализована простая последовательная программа на C++.
Все вычисления выполняются в одном потоке, без использования
параллелизма. Это задание нужно для того, чтобы понять базовый алгоритм
и иметь с чем сравнивать параллельную реализацию.

---

### Задание 2 — Параллельная версия с OpenMP
Во втором задании программа была распараллелена с помощью OpenMP.
Для этого использовались специальные директивы, которые позволяют
распределить вычисления между несколькими потоками процессора.

В ходе выполнения задания я использовала:
- `#pragma omp parallel`
- `#pragma omp parallel for`
- механизм `reduction`

Это позволило ускорить выполнение программы и корректно объединить
результаты, полученные в разных потоках.

---

### Задание 3 — Сравнение скорости работы
В третьем задании выполнено сравнение времени работы последовательной
и параллельной версий программы.

В результате было видно, что при увеличении объёма данных
параллельная версия выполняется быстрее, так как вычисления
распределяются между несколькими потоками CPU.

---

### Задание 4 — CUDA (теория)
Четвёртое задание посвящено технологии CUDA и выполнено в теоретическом формате.

CUDA — это технология компании NVIDIA, которая позволяет выполнять
параллельные вычисления на видеокарте (GPU).
В CUDA каждый поток обрабатывает отдельную часть данных, что делает
вычисления более быстрыми по сравнению с обычным выполнением на CPU.

В теории CUDA-программа работает следующим образом:
1. Подготавливаются данные на стороне CPU  
2. Выделяется память на GPU  
3. Данные копируются с CPU на GPU  
4. Запускается CUDA-ядро (kernel)  
5. Выполняются параллельные вычисления на GPU  
6. Результаты возвращаются обратно на CPU  

Практическую часть задания выполнить не удалось, так как в рабочей среде
не было подходящей видеокарты NVIDIA и установленного CUDA Toolkit.
Без этого компиляция и запуск CUDA-программ невозможны.


