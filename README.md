# Assignment 2 — Гетерогенная параллелизация (C++ / OpenMP / CUDA)
У меня выполнены **Задачи 1–3** (C++ + OpenMP).  
**Задача 4 (CUDA)** описана **теоретически**, т.к. на моём ПК нет подходящей среды для запуска CUDA (нет NVIDIA GPU и/или CUDA Toolkit).

---

## Структура проекта 
main2.cpp → Задача 2 (min/max + OpenMP)
main3.cpp → Задача 3 (сортировка выбором + OpenMP)
main4.cu → Задача 4 (CUDA, теория + попытка реализации)
.vscode, .gitignore — служебные
README.md — описание проекта

---

# Задача 1 — Теория: что такое гетерогенная параллелизация

**Гетерогенная параллелизация** — это подход, когда вычисления распределяются между **разными типами процессоров**:
* CPU - центральный процессор
* GPU - графический процессор 
CPU хорошо делает “умные” и последовательные части, а GPU очень быстро делает **массово-параллельные** операции.

## CPU vs GPU 
### CPU
* Меньше ядер (обычно 4–16, иногда больше)
* Каждое ядро “умное”: сложная логика, ветвления, кеши
* Хорош для:
  * последовательных алгоритмов
  * сложных условий `if/else`
  * управления программой (контроль, ввод/вывод, работа с ОС)

### GPU
* Очень много простых вычислительных ядер (сотни/тысячи)
* Идеален для операций, где **одно и то же действие повторяется много раз**
* Хорош для:
  * обработка изображений/видео
  * матрицы, нейросети, ML
  * моделирование, физика, расчёты

## Преимущества гетерогенной параллелизации
* ускорение тяжёлых вычислений (GPU берёт массовые операции)
* эффективность - CPU не “захлёбывается” на больших данных
* можно совмещать: CPU готовит данные, GPU быстро считает, CPU собирает результат

## Примеры реальных приложений
* Машинное обучение (обучение нейросетей)
* Компьютерное зрение (фильтры, детекция объектов)
* Научные расчёты (симуляции, CFD, молекулярная динамика)
* Рендеринг (графика, 3D)

---

# Задача 2 — Массив 10 000 чисел: min/max (sequential vs OpenMP)

## Что делает программа

1. Создаёт массив на **10 000 случайных чисел**
2. Находит **min** и **max**:

   * обычным циклом (последовательно)
   * параллельно с OpenMP
3. Замеряет время и сравнивает

## Как устроен код 

### 1) Генерация массива

Обычно это делается через `random_device`, `mt19937` и `uniform_int_distribution`:

* `mt19937` — генератор случайных чисел
* `uniform_int_distribution(lo, hi)` — равномерное распределение в диапазоне

### 2) Последовательный min/max

Классика:

* `mn = +∞` (например `numeric_limits<int>::max()`)
* `mx = -∞`
* один цикл по массиву и обновляем минимум/максимум

### 3) Параллельный min/max на OpenMP

если несколько потоков будут менять одну переменную `mn`/`mx` одновременно — будет гонка данных. поэтому используется **reduction** или локальные переменные.

Самый простой и правильный вариант:

* `reduction(min: mn)` и `reduction(max: mx)`

Пример идеи (как это работает):
* каждый поток считает свой локальный минимум/максимум
* в конце OpenMP объединяет результаты в один общий

### 4) Замер времени

Обычно используется:

* `chrono::high_resolution_clock::now()`
* разница `t2 - t1` = время выполнения

## Какие выводы обычно получаются

* На маленьких массивах ускорение может быть слабым из-за накладных расходов потоков.
* На больших массивах параллельная версия чаще быстрее.

---

# Задача 3 — Сортировка выбором (OpenMP)

## Алгоритм сортировки выбором (selection sort)

* на позиции `i` ищем минимальный элемент на отрезке `i..N-1`
* меняем местами `a[i]` и найденный минимум
* повторяем

Это **O(N²)**, поэтому на 10 000 элементов может быть довольно медленно.

## Последовательная версия

* два вложенных цикла
* внутренний ищет индекс минимума

## Параллельная версия 

Важно: сам внешний цикл `i` зависит от предыдущих перестановок, поэтому **полностью распараллелить selection sort сложно**. Поэтому:

* параллелим **поиск минимума** внутри внутреннего цикла (по `j`)
* а сам swap делаем один раз после поиска

Как это обычно делается:

* каждый поток ищет локальный минимум (значение + индекс)
* потом выбираем глобальный минимум среди локальных

Если сделать просто `#pragma omp parallel for` на внутреннем цикле и менять общий `minIndex` без защиты — будет ошибка (race condition).

## Проверка производительности

По заданию:

* массив **1000**
* массив **10000**
  Сравниваются времена:
* sequential selection sort
* parallel selection sort (поиск минимума распараллелен)

Ожидаемо:

* ускорение может быть не очень большим, потому что:

  * много синхронизаций
  * алгоритм сам по себе не очень дружит с параллельностью
  * накладные расходы OpenMP

---

# Задача 4 — CUDA: сортировка слиянием на GPU 

требовалось:

* разделить массив на части → каждый блок сортирует свой кусок
* потом выполнить параллельное слияние отсортированных частей
* замерить время на 10 000 и 100 000

## Почему у меня не получилось выполнить практику

CUDA работает только на GPU **NVIDIA** и требует установленного **CUDA Toolkit** (компилятор `nvcc`).
На моём ПК нет совместимой NVIDIA видеокарты и не установлен CUDA Toolkit / нет `nvcc`


## Как это должно работать 

1. CPU готовит данные
2. копируем массив в память GPU
3. запускаем kernel, который сортирует подмассивы
4. запускаем kernel для merge (слияния)
5. копируем результат обратно
